{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish the Model\n",
    "\n",
    "In this notebook, we aim to deploy the registered model from the ML Pipeline task.\n",
    "\n",
    "In the previous step, we manage to create an ML pipeline and run it from the DevOps Build Pipeline. To make that possible, we leveraged Service Principle Identities to log in into our Azure Account from the application to access the ML Workspace. In this notebook, we don't follow this but the Python version of this notebook (located at Score/deploy_model.py) uses the same log-in mechanism, as we need to run the  from the Release Pipeline.\n",
    "\n",
    "To register the model we follow these steps:\n",
    "1. Log in to Azure and get a hold on the Workspace\n",
    "1. Get the latest registered model from the Model Store\n",
    "1. Create a container image from the model\n",
    "1. Deploy the image as a Web Service on Azure Container Instance\n",
    "1. Test the deployed model behind the web service\n",
    "1. Create a Kubernetes cluster\n",
    "1. Deploy the image as a Web Service into the Kubernetes\n",
    "1. Test whether the model is working as expected behind the WebService within the Kubernetes cluster\n",
    "1. Convert this notebook into Python and register it into the Release Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:**:\n",
    "Similar to other notebooks, here are the requirements to run this notebook:\n",
    "\n",
    "In order to practice all parts of the following Notebook, you first need to get a free Azure credit. If you don't have it, you can simply obtain it through this link: https://azure.microsoft.com/en-us/free/\n",
    "\n",
    "You can run this notebook on your local latop, Azure Notebooks (notebooks.azure.com) or Notebook VMs:\n",
    "- Local Laptop - the following packages has to be installed:\n",
    "    - Azureml-SDK - with notebook,widget extensions\n",
    "    - tensorflow==1.13\n",
    "- Azure Notebooks:\n",
    "    - This is a free notebook, all of the packages for an ML experiment is installed\n",
    "- AzureML Notebook:\n",
    "    - This is a premium notebook that you can choose the VM type. Avoid using this feature for the workshop as you may burn your credit before the end or the workshop.\n",
    "\n",
    "Once you chose the execution environment, you need to create an Azure Machine Learning Service. Follow this instruction to build one:\n",
    "\n",
    "The following text is copied from: https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup#create-a-workspace\n",
    "\n",
    "An Azure Machine Learning workspace is a foundational resource in the cloud that you use to experiment, train, and deploy machine learning models. It ties your Azure subscription and resource group to an easily consumed object in the service.\n",
    "\n",
    "You create a workspace via the Azure portal, a web-based console for managing your Azure resources.\n",
    "\n",
    "1. Sign in to the Azure portal by using the credentials for the Azure subscription you use.\n",
    "1. In the upper-left corner of Azure portal, select + Create a resource.\n",
    "1. Create a new resource\n",
    "1. Use the search bar to find Machine Learning service workspace.\n",
    "1. Select Machine Learning service workspace.\n",
    "1. In the Machine Learning service workspace pane, select Create to begin.\n",
    "1. Provide the following information to configure your new workspace:\n",
    "    - **Field\tDescription**\n",
    "    - **Workspace name**: type in **FirstExample**.\n",
    "    - **Subscription**: Select the Azure subscription that you want to use. (Your free credit)\n",
    "    - **Resource group**: type in **MLOpsWorkshop**\n",
    "    - **Location**: type in **westus2**\n",
    "1. After you are finished configuring the workspace, select Create.\n",
    "When the process is finished, a deployment success message appears.\n",
    "1. To view the new workspace, select Go to resource.\n",
    "\n",
    "\n",
    "You can explore the resource from two view:\n",
    "1. https://portal.azure.com (you can access all resources including Azure ML)\n",
    "1. https://ml.azure.com (recently released - still in preview and dedicated to Azure ML)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import ContainerImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your subscription ID will be different replace the stirng with yours\n",
    "subscription_id = \"b198933e-f055-498f-958d-0726ab11eddb\"\n",
    "resource_group = \"MLOps_Template\"\n",
    "workspace_name = \"MLOps_template_ML\"\n",
    "workspace_region = \"West US 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Workspace class and check the azureml SDK version\n",
    "# exist_ok checks if workspace exists or not.\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MLOps_template_ML\n",
      "Azure region: westus2\n",
      "Subscription id: b198933e-f055-498f-958d-0726ab11eddb\n",
      "Resource group: MLOps_Template\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the registered model registered in the last session.\n",
    "\n",
    "You need to make sure the model_name is set property. In order to find out the model_name you registered in the previous session, go to portal.azure.com, click on your Workspace and the from the Asset panel, click on the Models. If you don't see any model registered here, you need to first run the previous lab located at (https://github.com/classicboyir/ml-pipelines/blob/master/MLPipeline_MNIST.ipynb). Clone this repo and follow the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = \"tf_mnist_pipeline_devops.model\"\n",
    "model_root = Model(ws, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Provide the dependencies required at the inference time.\n",
    "\n",
    "This code block generates the conda dependency file to load a TF model. You can find the script that is in charge of the inference task. You can check it at here **Score/score.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloofar.nayebi\\PROJECT\\10-AltaGas-MLops\\Avanade\\build-release-ci-cd\\score\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "#os.chdir('./score')\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "conda = None\n",
    "myenv = Environment(name=\"myenv\")\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=None,python_version='3.6.2', pip_packages=[\n",
    "     'azureml-defaults',\n",
    "     'inference-schema',\n",
    "     'numpy',\n",
    "     \"azureml-monitoring\",\n",
    "     'tensorflow==1.13.1'\n",
    "     ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Containerize the model\n",
    "\n",
    "In this task, it builds a docker image containing the model, the dependency file and also the score.py file. The image is registered at the Images section within your Workspace. You can explore it through portal.azure.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (Non-free subscription) Creating a Kubernetes Cluster\n",
    "\n",
    "In this step, we create one Kubernetes cluster to host the dockerized image and provide it through a web service.\n",
    "\n",
    "**Important Note**:\n",
    "This section requires you to upgrade your subscription from free to pay-as-you-go. Creation of Kubernetes cluster under free subscription is not supported as of now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing AKS service\n",
      "Succeeded\n",
      "Wall time: 644 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aks_name = 'aks-deployment'\n",
    "\n",
    "try:\n",
    "    kubeconfig = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    aks_target = kubeconfig\n",
    "    print('Found existing AKS service')\n",
    "except Exception:\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    print('Creating a new AKS service...')\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "\n",
    "    aks_target.wait_for_completion(show_output = True)\n",
    "    print(aks_target.provisioning_state)\n",
    "    print(aks_target.provisioning_errors)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(aks_target.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kubeconfig.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. (Non-free subscription) Registering the dockerized image as a Webservice on the Kubernetes cluster\n",
    "\n",
    "First, we provide the configuration for the web service. We enable app insights to be able to log and monitor the activities of our mode. We can also turn on the auto scaling feature to scale the container as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inf_config = InferenceConfig(entry_script='score.py', environment=myenv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the webservice, deleting the service to add a new one\n",
      "Old webservice is deleted\n",
      "Deploying the new web service\n",
      "Running...\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "This webservice is deployed\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# In this code block, we register the image under a webservice in Kubernetes cluster:\n",
    "\n",
    "aks_service_name ='mnist-webapp-service-monitored'\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(autoscale_enabled=True, \n",
    "                                                       autoscale_min_replicas=1,                                               cpu_cores=2, memory_gb=1, \n",
    "                                                       scoring_timeout_ms=5000, \n",
    "                                                       replica_max_concurrent_requests=2, \n",
    "                                                       max_request_wait_time=5000, \n",
    "                                                       enable_app_insights=True,\n",
    "                                                       collect_model_data=True)\n",
    "\n",
    "try:\n",
    "    aks_service = Webservice(name = aks_service_name, workspace = ws)\n",
    "    print('Found the webservice, deleting the service to add a new one')\n",
    "    aks_service.delete()\n",
    "    print('Old webservice is deleted')\n",
    "except Exception:\n",
    "    print(\"This webservice doesn't exist\")\n",
    "finally:\n",
    "    print('Deploying the new web service')\n",
    "    # aks_service = Webservice.deploy_from_image(workspace = ws, \n",
    "    #                                        name = aks_service_name,\n",
    "    #                                        image = image,\n",
    "    #                                        deployment_config = aks_config,\n",
    "    #                                        deployment_target = aks_target)\n",
    "    aks_service = Model.deploy(workspace=ws,\n",
    "                           name=aks_service_name,\n",
    "                           models = [model_root],\n",
    "                           inference_config=inf_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target,\n",
    "                           overwrite=True)\n",
    "\n",
    "\n",
    "    aks_service.wait_for_deployment(show_output = True)\n",
    "    print('This webservice is deployed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-11T21:28:49,361941101+00:00 - gunicorn/run \\n2020-08-11T21:28:49,364575907+00:00 - nginx/run \\n2020-08-11T21:28:49,363784505+00:00 - rsyslog/run \\n2020-08-11T21:28:49,365181509+00:00 - iot-server/run \\n/usr/sbin/nginx: /azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2020-08-11T21:28:49,439043991+00:00 - iot-server/finish 1 0\\n2020-08-11T21:28:49,440418494+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (10)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\nInitialized PySpark session.\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2020-08-11 21:28:51.519088: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\\n2020-08-11 21:28:51.523904: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294680000 Hz\\n2020-08-11 21:28:51.524645: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55afdcd06840 executing computations on platform Host. Devices:\\n2020-08-11 21:28:51.524669: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\\nmodel initializing at 21:28:51\\nFrom /azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse standard file APIs to check for files with this prefix.\\nRestoring parameters from azureml-models/tf_mnist_pipeline_devops.model/16/model/tf_mnist_pipeline_devops.model\\nmodel initialized at 21:28:51\\nUsers\\'s init has completed successfully\\n/azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\\n/azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\\n/azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\\n/azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\\n/azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\\n/azureml-envs/azureml_3d2424877914924cfc59568bb0efc769/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\\nSkipping middleware: dbg_model_info as it\\'s not enabled.\\nScoring timeout is found from os.environ: 5000 ms\\nSwagger file not present\\n404\\n127.0.0.1 - - [11/Aug/2020:21:28:54 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [11/Aug/2020:21:28:54 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [11/Aug/2020:21:29:02 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [11/Aug/2020:21:29:02 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aks_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always access the Webservice URL and the authentication keys using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://52.229.21.121:80/api/v1/service/mnist-webapp-service-monitored/score'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aks_service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('R8pMM9NYdysSKnwdyE87o18caaYAYQrd', 'IUehsMVUK76ySxKD2dIHhvzu1X4qrT4Q')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aks_service.get_keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
