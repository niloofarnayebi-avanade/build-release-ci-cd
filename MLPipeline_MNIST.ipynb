{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipelines\n",
    "\n",
    "A Machine Learning pipeline is a set of independent steps that each can have different compute, data, environment, etc. dependencies. Each step is treated as a separate run and all of the four aspects of a run (metrics, logs, snapshot and outputs) are stored independently. After the pipeline is created, it can be published as an API for later reuse.\n",
    "\n",
    "This gives you huge benefit as you have ultimate control over defining each step of the pipeline in a way that serves best for that particular step.\n",
    "\n",
    "ML Pipelines are some type of workflow orchestration tools. The main difference between ML Pipelines and regular job workflows (such as Azure Data Factory or Airflow) is that this workflow engine is designed to address ML needs. Therefore, if you have non-ML related workflow it's recommended you use generic workflow engines. You may call an ML Pipeline from a generic pipeline as a step.\n",
    "\n",
    "In this tutorial, we want to treat the MNIST model we trained in the previous example like a serious ML problem. We'd like to break the task into three parts:\n",
    "1. Downloading the dataset from the Yann Lecun website, unzip and normalize it and save it in a shared storage\n",
    "2. Train our 2-Layer Neural Net on the normalized data\n",
    "3. Register the model in case the performance of the new model is higher than the latest version of the model in the Model Registry\n",
    "4. Publish the pipeline as a bundle of the above steps as an API Endpoint\n",
    "\n",
    "At the end of this notebook, you'll build the following pipeline.\n",
    "![ML Pipeline](assets/MLOps_Pipeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining an ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.9.0\n",
      "Pipeline SDK-specific imports completed\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "print(\"Pipeline SDK-specific imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "# Your subscription ID will be different replace the stirng with yours\n",
    "subscription_id = \"b198933e-f055-498f-958d-0726ab11eddb\"\n",
    "resource_group = \"MLOps_Template\"\n",
    "workspace_name = \"MLOps_template_ML\"\n",
    "workspace_region = \"West US 2\"\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"e65922f9-4bd4-4f11-b1a3-48e89d75674e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Workspace class and check the azureml SDK version\n",
    "# exist_ok checks if workspace exists or not.\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MLOps_template_ML\n",
      "Azure region: westus2\n",
      "Subscription id: b198933e-f055-498f-958d-0726ab11eddb\n",
      "Resource group: MLOps_Template\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Stores\n",
    "\n",
    "As described in the previous section, Datastores are attached to workspaces and are used to store connection information to Azure storage services so you can refer to them by name and don't need to remember the connection information and secret used to connect to the storage services.\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the registered Datastores in your Workspace, login to **ml.azure.com**, in the left pane, under **Manage** section click on the **Datastores**. By default, you have two data stores registered, **workspaceblobstore** and **workspacefilestore**.\n",
    "\n",
    "We skip the **workspacefilestore** for now and only use **workspaceblobstore** for this exercise. **workspaceblobstore** is referring to the default Blob storage that is created at the creation of Workspace. **Blob storage** is a type of storage account that is used to keep any type of data from binary (image files) to csv or parquet (It's similar to **AWS S3**). At any time you can register a new Azure's storage account at your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blobstore's name: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the pointer to the default Blob storage.\n",
    "\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "\n",
    "## The code below also yields the same result:\n",
    "# def_blob_store = ws.get_default_datastore()\n",
    "\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An object from DataReference class represents a path within a Datastore. So in the example below, you're explaining that the MNIST data should be available in the **mnist_datainput** parth under the **workspaceblobstore** container in the Azure storage account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob_input_data = DataReference(\n",
    "#     datastore=def_blob_store,\n",
    "#     data_reference_name=\"mnist_datainput\",\n",
    "#     path_on_datastore=\"mnist_datainput\")\n",
    "# \n",
    "# print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure the compute targets are created.\n",
    "\n",
    "In this example, we want to have two types of compute environment, the first compute type is a CPU type and the other is a GPU type cluster each with 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded...............\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 1, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-07-22T21:34:48.305000+00:00', 'errors': None, 'creationTime': '2020-07-22T21:32:51.796259+00:00', 'modifiedTime': '2020-07-22T21:33:37.668392+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': ''}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GPU cluster of type NV6 with 1 node. (due to subscription's limitations we stick to 1 node)\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target_cpu = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    # CPU: Standard_D3_v2\n",
    "    # GPU: Standard_NV6\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           max_nodes=1,\n",
    "                                                           min_nodes=1)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target_cpu = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target_cpu.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target_cpu.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commenting this as we want to only use one compute target to make things faster. Try this later if you like to train on GPU.\n",
    "\n",
    "# # choose a name for your cluster\n",
    "# cluster_name = \"gpucluster\"\n",
    "# \n",
    "# try:\n",
    "#     compute_target_gpu = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "#     print('Found existing compute target.')\n",
    "# except ComputeTargetException:\n",
    "#     print('Creating a new compute target...')\n",
    "#     # CPU: Standard_D3_v2\n",
    "#     # GPU: Standard_NV6\n",
    "#     compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NV6', \n",
    "#                                                            max_nodes=1,\n",
    "#                                                            min_nodes=1)\n",
    "# \n",
    "#     # create the cluster\n",
    "#     compute_target_gpu = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "# \n",
    "#     compute_target_gpu.wait_for_completion(show_output=True)\n",
    "# \n",
    "# # use get_status() to get a detailed status for the current cluster. \n",
    "# print(compute_target_gpu.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpucluster\n"
     ]
    }
   ],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipelineData is a way to define data dependancies in an ML Pipeline. In this example, we want to first download the MNIST data into a directory called raw_data and then save the processed and normalized numpy objects into a subdirectory called Processed. This PipelineData object will be used as the output of the first step named Data Extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_processed_mnist_data"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_mnist_data = PipelineData(\"processed_mnist_data\", datastore=def_blob_store)\n",
    "processed_mnist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step is a regular Python script, and can be executed on a CPU node with no prepackaged ML environment requirment, we stick to the default configurations.\n",
    "\n",
    "The configurations below, first deploys a CPU based linux docker image on the VM and then installs 'azureml-sdk' and 'numpy' packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk',\n",
    "                                                                                          'numpy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the first step by defining an object from PythonScriptStep class. Under the hood, it calls the extract.py file as the entry script and we pass the **processed_mnist_data** object as a parameter to the script.\n",
    "\n",
    "**outputs** parameter defines the data output dependencies that in this case, we have an object of DataPipeline **processed_mnist_data** as the output dependency.\n",
    "\n",
    "As the script can run on a CPU node, we don't waste our money by running it on a GPU node. Therefore, we select **compute_target_cpu** as the target compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extraction Step created\n"
     ]
    }
   ],
   "source": [
    "# source directory\n",
    "source_directory = 'DataExtraction'\n",
    "\n",
    "extractDataStep = PythonScriptStep(\n",
    "    script_name=\"extract.py\", \n",
    "    arguments=[\"--output_extract\", processed_mnist_data],\n",
    "    outputs=[processed_mnist_data],\n",
    "    compute_target=compute_target_cpu, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config)\n",
    "\n",
    "print(\"Data Extraction Step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to run our Tensorflow job to train our very best MNIST classifier. As this is a TF job, we can leverage Estimator classes such as  **azureml.train.dnn.TensorFlow**. Moreover, the inputs argument instructs the Pipeline what should be the dependency before executing this step. As the **processed_mnist_data** PipelineData object is provided as the output for the step above and input for this step, the Pipeline engine will execute the Training step after the Data Extraction step.\n",
    "\n",
    "As a TF job, we can leverage our GPU node to boost up the computational performance of the training step. So we provide the GPU cluster as the compute target.\n",
    "\n",
    "The TF estimator support TF 1. If your script is based on TF 2, then you can use the **PythonScriptStep** and provide your custom docker image or pip install TF 2 on a base GPU image.\n",
    "\n",
    "We provide two arguments, **release_id** and **model_name**. **release_id** helps us to logically tag the run to a number that later can be retrieved. You can think of the **release_id** as the version number. In the 3rd day, you'll use the release pipeline to populate the release_id. **model_name** as it's name suggests instructs the code on what name to use to save the model in the run->output section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "source_directory = 'Training'\n",
    "est = TensorFlow(source_directory=source_directory,\n",
    "                 compute_target=compute_target_cpu,\n",
    "                 entry_script='train.py', \n",
    "                 use_gpu=False, \n",
    "                 framework_version='1.13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Step is Completed\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import EstimatorStep\n",
    "\n",
    "trainingStep = EstimatorStep(name=\"Training-Step\",\n",
    "                             estimator=est,\n",
    "                             estimator_entry_script_arguments=[\"--input_data_location\", processed_mnist_data,\n",
    "                                                               '--batch-size', 50,\n",
    "                                                               '--first-layer-neurons', 300,\n",
    "                                                               '--second-layer-neurons', 100,\n",
    "                                                               '--learning-rate', 0.01,\n",
    "                                                               \"--release_id\", 0,\n",
    "                                                               '--model_name', 'tf_mnist_pipeline.model'],\n",
    "                             runconfig_pipeline_params=None,\n",
    "                             inputs=[processed_mnist_data],\n",
    "                             compute_target=compute_target_cpu)\n",
    "\n",
    "print(\"Model Training Step is Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we want to evaluate and register the model. Similar to the first step, we only need a CPU node to accomplish this task as we're running a regular python script with no ML dependencies. So we instantiate an object from **PythonScriptStep** class and provide **evaluate_model.py** as the entry script. \n",
    "\n",
    "The two arguments we provided in the step above are used here to retrieve the model saved in the run->output section of the experiment. Using release id, we can retrieve all other models and check if this model is outperforming them or not. If not we don't register this model into the model registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation and Registration Step is Created\n"
     ]
    }
   ],
   "source": [
    "# source directory\n",
    "source_directory = 'RegisterModel'\n",
    "\n",
    "modelEvalReg = PythonScriptStep(\n",
    "    name=\"Evaluate and Register Model\",\n",
    "    script_name=\"evaluate_model.py\", \n",
    "    arguments=[\"--release_id\", 0,\n",
    "               '--model_name', 'tf_mnist_pipeline.model'],\n",
    "    compute_target=compute_target_cpu, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config)\n",
    "print(\"Model Evaluation and Registration Step is Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this step doesn't have any inputs or outputs data dependancies, the Pipeline engine will execute it in parallel with the prevous two steps. However, logically we should execute this after the training step. Therefore, we use the below command the instruct the Pipeline engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvalReg.run_after(trainingStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all of the pipeline steps are defined. We can build the Pipeline class which defines how the pipeline should be executed.\n",
    "\n",
    "Pipelines are loosely coupled with Experiments. At run time you can define to which Experiment this pipeline execution should be connected. For this we define/connect to **MNIST-Model-Manual-Pipeline** experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'azureml-defaults' is not included in the pip package list in the environment definition in RunConfiguration. This may result in job failures during execution.\n",
      "WARNING - 'azureml-defaults' is not included in the pip package list in the environment definition in RunConfiguration. This may result in job failures during execution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step extract.py [c11c26ce][b7d35166-f8b3-40ce-b825-51f34cb68afe], (This step will run and generate new outputs)\n",
      "Created step Training-Step [d276fba9][114fa064-33a8-44ed-a9bc-2ecd8056a940], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [354d46ec][a393d26f-8711-440c-b088-5964de8bce40], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun e953c74d-177e-4fb3-88de-fe5e9263b978\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/e953c74d-177e-4fb3-88de-fe5e9263b978?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "pipeline = Pipeline(workspace=ws, steps=[extractDataStep, trainingStep, modelEvalReg])\n",
    "pipeline_run = Experiment(ws, 'MNIST-Model-Manual-Pipeline').submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168bb75af57c4211ab74222b80d5a710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/e953c74d-177e-4fb3-88de-fe5e9263b978?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\", \"run_id\": \"e953c74d-177e-4fb3-88de-fe5e9263b978\", \"run_properties\": {\"run_id\": \"e953c74d-177e-4fb3-88de-fe5e9263b978\", \"created_utc\": \"2020-07-22T22:21:16.990209Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-07-22T22:32:36.726269Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.e953c74d-177e-4fb3-88de-fe5e9263b978/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=s0rM%2BO14p8Kk%2BBamLo8Zgwh5ZB8qbChzeXYQRSyWTTY%3D&st=2020-07-23T17%3A17%3A38Z&se=2020-07-24T01%3A27%3A38Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.e953c74d-177e-4fb3-88de-fe5e9263b978/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=uhTzEUmpoByAfoOLqY0e7l2ehkVREWcLeEt8KY3VAos%3D&st=2020-07-23T17%3A17%3A38Z&se=2020-07-24T01%3A27%3A38Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.e953c74d-177e-4fb3-88de-fe5e9263b978/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=CSsjc70oap9rTxmQGzq0p4VCgyhF%2Fqf00%2B5THz6XZqk%3D&st=2020-07-23T17%3A17%3A38Z&se=2020-07-24T01%3A27%3A38Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:11:19\"}, \"child_runs\": [{\"run_id\": \"329b2954-ed21-493f-8ee9-d2776f451dc0\", \"name\": \"extract.py\", \"status\": \"Finished\", \"start_time\": \"2020-07-22T22:26:49.939193Z\", \"created_time\": \"2020-07-22T22:21:27.648116Z\", \"end_time\": \"2020-07-22T22:28:46.350697Z\", \"duration\": \"0:07:18\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-07-22T22:21:27.648116Z\", \"is_reused\": \"\"}, {\"run_id\": \"3805a880-2419-494a-9b02-80e6d6f00f9d\", \"name\": \"Training-Step\", \"status\": \"Finished\", \"start_time\": \"2020-07-22T22:29:03.906615Z\", \"created_time\": \"2020-07-22T22:28:49.27194Z\", \"end_time\": \"2020-07-22T22:31:47.855648Z\", \"duration\": \"0:02:58\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-07-22T22:28:49.27194Z\", \"is_reused\": \"\"}, {\"run_id\": \"f230bd88-914b-41fb-9981-b073d9c91168\", \"name\": \"Evaluate and Register Model\", \"status\": \"Finished\", \"start_time\": \"2020-07-22T22:32:07.189085Z\", \"created_time\": \"2020-07-22T22:31:52.343161Z\", \"end_time\": \"2020-07-22T22:32:31.305839Z\", \"duration\": \"0:00:38\", \"run_number\": 4, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-07-22T22:31:52.343161Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-07-22 22:21:27Z] Submitting 1 runs, first five are: c11c26ce:329b2954-ed21-493f-8ee9-d2776f451dc0\\n[2020-07-22 22:28:48Z] Completing processing run id 329b2954-ed21-493f-8ee9-d2776f451dc0.\\n[2020-07-22 22:28:48Z] Submitting 1 runs, first five are: d276fba9:3805a880-2419-494a-9b02-80e6d6f00f9d\\n[2020-07-22 22:31:50Z] Completing processing run id 3805a880-2419-494a-9b02-80e6d6f00f9d.\\n[2020-07-22 22:31:52Z] Submitting 1 runs, first five are: 354d46ec:f230bd88-914b-41fb-9981-b073d9c91168\\n[2020-07-22 22:32:35Z] Completing processing run id f230bd88-914b-41fb-9981-b073d9c91168.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"c11c26ce\": {\"node_id\": \"c11c26ce\", \"name\": \"extract.py\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"329b2954-ed21-493f-8ee9-d2776f451dc0\"}, \"d276fba9\": {\"node_id\": \"d276fba9\", \"name\": \"Training-Step\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"3805a880-2419-494a-9b02-80e6d6f00f9d\"}, \"354d46ec\": {\"node_id\": \"354d46ec\", \"name\": \"Evaluate and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"f230bd88-914b-41fb-9981-b073d9c91168\"}}, \"edges\": [{\"source_node_id\": \"c11c26ce\", \"source_node_name\": \"extract.py\", \"source_name\": \"processed_mnist_data\", \"target_name\": \"processed_mnist_data\", \"dst_node_id\": \"d276fba9\", \"dst_node_name\": \"Training-Step\"}, {\"source_node_id\": \"d276fba9\", \"source_node_name\": \"Training-Step\", \"source_name\": \"_run_after_output\", \"target_name\": \"_run_after_input_0\", \"dst_node_id\": \"354d46ec\", \"dst_node_name\": \"Evaluate and Register Model\"}], \"child_runs\": [{\"run_id\": \"329b2954-ed21-493f-8ee9-d2776f451dc0\", \"name\": \"extract.py\", \"status\": \"Finished\", \"start_time\": \"2020-07-22T22:26:49.939193Z\", \"created_time\": \"2020-07-22T22:21:27.648116Z\", \"end_time\": \"2020-07-22T22:28:46.350697Z\", \"duration\": \"0:07:18\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-07-22T22:21:27.648116Z\", \"is_reused\": \"\"}, {\"run_id\": \"3805a880-2419-494a-9b02-80e6d6f00f9d\", \"name\": \"Training-Step\", \"status\": \"Finished\", \"start_time\": \"2020-07-22T22:29:03.906615Z\", \"created_time\": \"2020-07-22T22:28:49.27194Z\", \"end_time\": \"2020-07-22T22:31:47.855648Z\", \"duration\": \"0:02:58\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-07-22T22:28:49.27194Z\", \"is_reused\": \"\"}, {\"run_id\": \"f230bd88-914b-41fb-9981-b073d9c91168\", \"name\": \"Evaluate and Register Model\", \"status\": \"Finished\", \"start_time\": \"2020-07-22T22:32:07.189085Z\", \"created_time\": \"2020-07-22T22:31:52.343161Z\", \"end_time\": \"2020-07-22T22:32:31.305839Z\", \"duration\": \"0:00:38\", \"run_number\": 4, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-07-22T22:31:52.343161Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.9.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to any run, Pipeline runs are non-blocking. However, if you automate this job, you like your code to wait until the pipeline is constructed and executed. So you'd use the below command to make the run execution blocking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: e953c74d-177e-4fb3-88de-fe5e9263b978\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/e953c74d-177e-4fb3-88de-fe5e9263b978?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 329b2954-ed21-493f-8ee9-d2776f451dc0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/329b2954-ed21-493f-8ee9-d2776f451dc0?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\n",
      "StepRun( extract.py ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/07/22 22:21:47 Downloading source code...\n",
      "2020/07/22 22:21:49 Finished downloading source code\n",
      "2020/07/22 22:21:50 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/07/22 22:21:51 Successfully set up Docker network: acb_default_network\n",
      "2020/07/22 22:21:51 Setting up Docker configuration...\n",
      "2020/07/22 22:21:52 Successfully set up Docker configuration\n",
      "2020/07/22 22:21:52 Logging in to registry: mlopstemplat9c2637c6.azurecr.io\n",
      "2020/07/22 22:21:53 Successfully logged into mlopstemplat9c2637c6.azurecr.io\n",
      "2020/07/22 22:21:53 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/07/22 22:21:53 Scanning for dependencies...\n",
      "2020/07/22 22:21:55 Successfully scanned dependencies\n",
      "2020/07/22 22:21:55 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1@sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      "sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "fe703b657a32: Pulling fs layer\n",
      "f9df1fafd224: Pulling fs layer\n",
      "a645a4b887f9: Pulling fs layer\n",
      "57db7fe0b522: Pulling fs layer\n",
      "20b5fabe4f63: Pulling fs layer\n",
      "22898513a7dc: Pulling fs layer\n",
      "b77f65fcd9d7: Pulling fs layer\n",
      "132ebd5cd5ca: Pulling fs layer\n",
      "01991399be72: Pulling fs layer\n",
      "60c58ca14ef7: Pulling fs layer\n",
      "ca339bb1ce1b: Pulling fs layer\n",
      "57db7fe0b522: Waiting\n",
      "20b5fabe4f63: Waiting\n",
      "22898513a7dc: Waiting\n",
      "b77f65fcd9d7: Waiting\n",
      "132ebd5cd5ca: Waiting\n",
      "01991399be72: Waiting\n",
      "60c58ca14ef7: Waiting\n",
      "ca339bb1ce1b: Waiting\n",
      "a645a4b887f9: Verifying Checksum\n",
      "a645a4b887f9: Download complete\n",
      "f9df1fafd224: Verifying Checksum\n",
      "f9df1fafd224: Download complete\n",
      "57db7fe0b522: Verifying Checksum\n",
      "57db7fe0b522: Download complete\n",
      "fe703b657a32: Verifying Checksum\n",
      "fe703b657a32: Download complete\n",
      "22898513a7dc: Verifying Checksum\n",
      "22898513a7dc: Download complete\n",
      "b77f65fcd9d7: Verifying Checksum\n",
      "b77f65fcd9d7: Download complete\n",
      "132ebd5cd5ca: Verifying Checksum\n",
      "132ebd5cd5ca: Download complete\n",
      "60c58ca14ef7: Verifying Checksum\n",
      "60c58ca14ef7: Download complete\n",
      "ca339bb1ce1b: Verifying Checksum\n",
      "ca339bb1ce1b: Download complete\n",
      "01991399be72: Verifying Checksum\n",
      "01991399be72: Download complete\n",
      "20b5fabe4f63: Verifying Checksum\n",
      "20b5fabe4f63: Download complete\n",
      "fe703b657a32: Pull complete\n",
      "f9df1fafd224: Pull complete\n",
      "a645a4b887f9: Pull complete\n",
      "57db7fe0b522: Pull complete\n",
      "20b5fabe4f63: Pull complete\n",
      "22898513a7dc: Pull complete\n",
      "b77f65fcd9d7: Pull complete\n",
      "132ebd5cd5ca: Pull complete\n",
      "01991399be72: Pull complete\n",
      "60c58ca14ef7: Pull complete\n",
      "ca339bb1ce1b: Pull complete\n",
      "Digest: sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1@sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      " ---> a0dab4f7c804\n",
      "Step 2/15 : USER root\n",
      " ---> Running in db4460fbfac2\n",
      "Removing intermediate container db4460fbfac2\n",
      " ---> 9ec4d061df39\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 409fa8106786\n",
      "Removing intermediate container 409fa8106786\n",
      " ---> ba6ac152f138\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 99156bb4922e\n",
      "Removing intermediate container 99156bb4922e\n",
      " ---> 6f76488d7915\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 2a631c272529\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 8c3be4c2f105\n",
      "Removing intermediate container 8c3be4c2f105\n",
      " ---> e290d204b252\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> dee2a42585c5\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 085a844e7ab2\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ######4    |  64% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 133 KB    |            |   0% \n",
      "ca-certificates-2020 | 133 KB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | #8         |  18% \n",
      "python-3.6.2         | 27.0 MB   | ####8      |  48% \n",
      "python-3.6.2         | 27.0 MB   | #######9   |  80% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "setuptools-49.2.0    | 929 KB    |            |   0% \n",
      "setuptools-49.2.0    | 929 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "pip-20.1.1           | 2.0 MB    |            |   0% \n",
      "pip-20.1.1           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.mktpzse6.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-sdk~=1.9.0\n",
      "  Downloading azureml_sdk-1.9.0-py3-none-any.whl (4.4 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting azureml-train~=1.9.0\n",
      "  Downloading azureml_train-1.9.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azureml-pipeline~=1.9.0\n",
      "  Downloading azureml_pipeline-1.9.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting azureml-dataprep[fuse]<1.10.0a,>=1.9.0a\n",
      "  Downloading azureml_dataprep-1.9.3-py3-none-any.whl (27.7 MB)\n",
      "Collecting azureml-core~=1.9.0\n",
      "  Downloading azureml_core-1.9.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting azureml-train-automl-client~=1.9.0\n",
      "  Downloading azureml_train_automl_client-1.9.0.post1-py3-none-any.whl (92 kB)\n",
      "Collecting azureml-train-core~=1.9.0\n",
      "  Downloading azureml_train_core-1.9.0-py3-none-any.whl (8.6 MB)\n",
      "Collecting azureml-pipeline-core~=1.9.0\n",
      "  Downloading azureml_pipeline_core-1.9.0-py3-none-any.whl (290 kB)\n",
      "Collecting azureml-pipeline-steps~=1.9.0\n",
      "  Downloading azureml_pipeline_steps-1.9.0-py3-none-any.whl (57 kB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.5.0-py3-none-any.whl (22 kB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.2.1\n",
      "  Downloading azureml_dataprep_native-14.2.1-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.14-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.2-py2.py3-none-any.whl (144 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.17-py2.py3-none-any.whl (84 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.1.0-py2.py3-none-any.whl (892 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.1.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting azure-mgmt-network~=10.0\n",
      "  Downloading azure_mgmt_network-10.2.0-py2.py3-none-any.whl (8.6 MB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting ruamel.yaml>0.16.7\n",
      "  Downloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azureml-telemetry~=1.9.0\n",
      "  Downloading azureml_telemetry-1.9.0-py3-none-any.whl (29 kB)\n",
      "Collecting azureml-automl-core~=1.9.0\n",
      "  Downloading azureml_automl_core-1.9.0.post1-py3-none-any.whl (140 kB)\n",
      "Collecting flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "Collecting azureml-train-restclients-hyperdrive~=1.9.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.9.0-py3-none-any.whl (18 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.7.0-py2.py3-none-any.whl (121 kB)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.4.1-py2.py3-none-any.whl (48 kB)\n",
      "Collecting six>=1.6\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.9.0->azureml-sdk~=1.9.0->-r /azureml-environment-setup/condaenv.mktpzse6.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548 kB)\n",
      "Collecting applicationinsights\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: fusepy\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=af7956ff854d29e5d7d2aa86e001a3c5bf19f303c7c16c93c2ea9ec79de0c3f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built fusepy\n",
      "Installing collected packages: mccabe, pycodestyle, entrypoints, pyflakes, flake8, chardet, urllib3, idna, requests, oauthlib, requests-oauthlib, six, isodate, msrest, pycparser, cffi, cryptography, python-dateutil, PyJWT, adal, msrestazure, azureml-train-restclients-hyperdrive, azure-common, azure-mgmt-keyvault, websocket-client, docker, contextlib2, jeepney, SecretStorage, pyopenssl, azure-mgmt-resource, azure-mgmt-containerregistry, azure-mgmt-storage, jmespath, pyasn1, ndg-httpsclient, azure-graphrbac, azure-mgmt-network, zipp, importlib-metadata, jsonpickle, backports.weakref, backports.tempfile, pytz, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-authorization, pathspec, azureml-core, applicationinsights, azureml-telemetry, azureml-train-core, azureml-train, azureml-pipeline-core, azure-core, msal, portalocker, msal-extensions, azure-identity, cloudpickle, azureml-dataprep-native, distro, dotnetcore2, fusepy, azureml-dataprep, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-steps, azureml-pipeline, azureml-sdk, numpy\n",
      "Successfully installed PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.7.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-network-10.2.0 azure-mgmt-resource-10.1.0 azure-mgmt-storage-11.1.0 azureml-automl-core-1.9.0.post1 azureml-core-1.9.0 azureml-dataprep-1.9.3 azureml-dataprep-native-14.2.1 azureml-pipeline-1.9.0 azureml-pipeline-core-1.9.0 azureml-pipeline-steps-1.9.0 azureml-sdk-1.9.0 azureml-telemetry-1.9.0 azureml-train-1.9.0 azureml-train-automl-client-1.9.0.post1 azureml-train-core-1.9.0 azureml-train-restclients-hyperdrive-1.9.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 cloudpickle-1.5.0 contextlib2-0.6.0.post1 cryptography-3.0 distro-1.5.0 docker-4.2.2 dotnetcore2-2.1.14 entrypoints-0.3 flake8-3.7.9 fusepy-3.0.1 idna-2.10 importlib-metadata-1.7.0 isodate-0.6.0 jeepney-0.4.3 jmespath-0.10.0 jsonpickle-1.4.1 mccabe-0.6.1 msal-1.4.1 msal-extensions-0.1.3 msrest-0.6.17 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.1 oauthlib-3.1.0 pathspec-0.8.0 portalocker-1.7.1 pyasn1-0.4.8 pycodestyle-2.5.0 pycparser-2.20 pyflakes-2.1.1 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 six-1.15.0 urllib3-1.25.10 websocket-client-0.57.0 zipp-3.1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 085a844e7ab2\n",
      " ---> d30646392485\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94/bin:$PATH\n",
      " ---> Running in 1c1ae12bfa17\n",
      "Removing intermediate container 1c1ae12bfa17\n",
      " ---> 940c6373bd01\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94\n",
      " ---> Running in 0d4d98da47c5\n",
      "Removing intermediate container 0d4d98da47c5\n",
      " ---> dfae9c20af80\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 81d2a6ed2618\n",
      "Removing intermediate container 81d2a6ed2618\n",
      " ---> e1103bbf1787\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 8780c32c4931\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 977e6a50a464\n",
      "Removing intermediate container 977e6a50a464\n",
      " ---> 7dc98d4c1fef\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in c63c33b6f21b\n",
      "Removing intermediate container c63c33b6f21b\n",
      " ---> 0974a93f4ccf\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in bfb33859f142\n",
      "Removing intermediate container bfb33859f142\n",
      " ---> d0cf7def5ab3\n",
      "Successfully built d0cf7def5ab3\n",
      "Successfully tagged mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5:latest\n",
      "2020/07/22 22:24:59 Successfully executed container: acb_step_0\n",
      "2020/07/22 22:24:59 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/07/22 22:24:59 Pushing image: mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5:latest, attempt 1\n",
      "The push refers to repository [mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5]\n",
      "884eea2e37f8: Preparing\n",
      "5b8771f4580e: Preparing\n",
      "2d2766ad9331: Preparing\n",
      "958301798a15: Preparing\n",
      "f79348351509: Preparing\n",
      "68568d9936c3: Preparing\n",
      "f5aa53607bc1: Preparing\n",
      "07eae5ad8c0b: Preparing\n",
      "facf43cddd83: Preparing\n",
      "69a9bdc813b0: Preparing\n",
      "7e2b9752143f: Preparing\n",
      "63a67842a4c7: Preparing\n",
      "ae3a847dbd6b: Preparing\n",
      "4ae3adcb66cb: Preparing\n",
      "aa6685385151: Preparing\n",
      "0040d8f00d7e: Preparing\n",
      "9e6f810a2aab: Preparing\n",
      "68568d9936c3: Waiting\n",
      "f5aa53607bc1: Waiting\n",
      "07eae5ad8c0b: Waiting\n",
      "facf43cddd83: Waiting\n",
      "4ae3adcb66cb: Waiting\n",
      "69a9bdc813b0: Waiting\n",
      "7e2b9752143f: Waiting\n",
      "63a67842a4c7: Waiting\n",
      "aa6685385151: Waiting\n",
      "ae3a847dbd6b: Waiting\n",
      "9e6f810a2aab: Waiting\n",
      "0040d8f00d7e: Waiting\n",
      "f79348351509: Pushed\n",
      "884eea2e37f8: Pushed\n",
      "958301798a15: Pushed\n",
      "2d2766ad9331: Pushed\n",
      "68568d9936c3: Pushed\n",
      "f5aa53607bc1: Pushed\n",
      "07eae5ad8c0b: Pushed\n",
      "\n",
      "63a67842a4c7: Pushed\n",
      "7e2b9752143f: Pushed\n",
      "facf43cddd83: Pushed\n",
      "4ae3adcb66cb: Pushed\n",
      "aa6685385151: Pushed\n",
      "0040d8f00d7e: Pushed\n",
      "69a9bdc813b0: Pushed\n",
      "9e6f810a2aab: Pushed\n",
      "ae3a847dbd6b: Pushed\n",
      "5b8771f4580e: Pushed\n",
      "latest: digest: sha256:5ad4c6cc73968982b57bceab23f46f13cfabb51a13e0184bea30c22104c89a53 size: 3883\n",
      "2020/07/22 22:26:31 Successfully pushed image: mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5:latest\n",
      "2020/07/22 22:26:31 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 186.456609)\n",
      "2020/07/22 22:26:31 Populating digests for step ID: acb_step_0...\n",
      "2020/07/22 22:26:33 Successfully populated digests for step ID: acb_step_0\n",
      "2020/07/22 22:26:33 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 91.664354)\n",
      "2020/07/22 22:26:33 The following dependencies were found:\n",
      "2020/07/22 22:26:33 \n",
      "- image:\n",
      "    registry: mlopstemplat9c2637c6.azurecr.io\n",
      "    repository: azureml/azureml_2e1aa647468113323a439077734657c5\n",
      "    tag: latest\n",
      "    digest: sha256:5ad4c6cc73968982b57bceab23f46f13cfabb51a13e0184bea30c22104c89a53\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20200423.v1\n",
      "    digest: sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      "  git: {}\n",
      "\n",
      "Run ID: cc1 was successful after 4m47s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      "========================================================================================================================\n",
      "2020-07-22T22:26:49Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2020-07-22T22:26:49Z Starting output-watcher...\n",
      "2020-07-22T22:26:49Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-07-22T22:26:49Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_2e1aa647468113323a439077734657c5\n",
      "fe703b657a32: Pulling fs layer\n",
      "f9df1fafd224: Pulling fs layer\n",
      "a645a4b887f9: Pulling fs layer\n",
      "57db7fe0b522: Pulling fs layer\n",
      "20b5fabe4f63: Pulling fs layer\n",
      "22898513a7dc: Pulling fs layer\n",
      "b77f65fcd9d7: Pulling fs layer\n",
      "132ebd5cd5ca: Pulling fs layer\n",
      "01991399be72: Pulling fs layer\n",
      "60c58ca14ef7: Pulling fs layer\n",
      "ca339bb1ce1b: Pulling fs layer\n",
      "d65aba8e6e67: Pulling fs layer\n",
      "aa0138759046: Pulling fs layer\n",
      "5fdfcf6a8a47: Pulling fs layer\n",
      "296333b9243a: Pulling fs layer\n",
      "0dfde38dac94: Pulling fs layer\n",
      "02b7cf7b4c55: Pulling fs layer\n",
      "57db7fe0b522: Waiting\n",
      "20b5fabe4f63: Waiting\n",
      "22898513a7dc: Waiting\n",
      "b77f65fcd9d7: Waiting\n",
      "132ebd5cd5ca: Waiting\n",
      "01991399be72: Waiting\n",
      "60c58ca14ef7: Waiting\n",
      "ca339bb1ce1b: Waiting\n",
      "d65aba8e6e67: Waiting\n",
      "aa0138759046: Waiting\n",
      "5fdfcf6a8a47: Waiting\n",
      "296333b9243a: Waiting\n",
      "0dfde38dac94: Waiting\n",
      "02b7cf7b4c55: Waiting\n",
      "f9df1fafd224: Verifying Checksum\n",
      "f9df1fafd224: Download complete\n",
      "a645a4b887f9: Download complete\n",
      "57db7fe0b522: Verifying Checksum\n",
      "57db7fe0b522: Download complete\n",
      "fe703b657a32: Verifying Checksum\n",
      "fe703b657a32: Download complete\n",
      "22898513a7dc: Verifying Checksum\n",
      "22898513a7dc: Download complete\n",
      "20b5fabe4f63: Verifying Checksum\n",
      "20b5fabe4f63: Download complete\n",
      "b77f65fcd9d7: Verifying Checksum\n",
      "b77f65fcd9d7: Download complete\n",
      "60c58ca14ef7: Verifying Checksum\n",
      "60c58ca14ef7: Download complete\n",
      "132ebd5cd5ca: Verifying Checksum\n",
      "132ebd5cd5ca: Download complete\n",
      "ca339bb1ce1b: Verifying Checksum\n",
      "ca339bb1ce1b: Download complete\n",
      "d65aba8e6e67: Verifying Checksum\n",
      "d65aba8e6e67: Download complete\n",
      "aa0138759046: Verifying Checksum\n",
      "aa0138759046: Download complete\n",
      "5fdfcf6a8a47: Verifying Checksum\n",
      "5fdfcf6a8a47: Download complete\n",
      "296333b9243a: Verifying Checksum\n",
      "296333b9243a: Download complete\n",
      "02b7cf7b4c55: Verifying Checksum\n",
      "02b7cf7b4c55: Download complete\n",
      "01991399be72: Verifying Checksum\n",
      "01991399be72: Download complete\n",
      "0dfde38dac94: Verifying Checksum\n",
      "0dfde38dac94: Download complete\n",
      "fe703b657a32: Pull complete\n",
      "f9df1fafd224: Pull complete\n",
      "a645a4b887f9: Pull complete\n",
      "57db7fe0b522: Pull complete\n",
      "20b5fabe4f63: Pull complete\n",
      "22898513a7dc: Pull complete\n",
      "b77f65fcd9d7: Pull complete\n",
      "132ebd5cd5ca: Pull complete\n",
      "01991399be72: Pull complete\n",
      "60c58ca14ef7: Pull complete\n",
      "ca339bb1ce1b: Pull complete\n",
      "d65aba8e6e67: Pull complete\n",
      "aa0138759046: Pull complete\n",
      "5fdfcf6a8a47: Pull complete\n",
      "296333b9243a: Pull complete\n",
      "0dfde38dac94: Pull complete\n",
      "02b7cf7b4c55: Pull complete\n",
      "Digest: sha256:5ad4c6cc73968982b57bceab23f46f13cfabb51a13e0184bea30c22104c89a53\n",
      "Status: Downloaded newer image for mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5:latest\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "[2020-07-22T22:28:12.881177] Entering context manager injector.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 111\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ extract.py ] with arguments: ['--output_extract', '/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data']\n",
      "After variable expansion, calling script [ extract.py ] with arguments: ['--output_extract', '/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data']\n",
      "\n",
      "Argument 1: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data\n",
      "Files are downloaded to /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data/raw_files/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized numpy binary files are saved at: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 111\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.7004928588867188 seconds\n",
      "2020/07/22 22:28:27 Process Exiting with Code:  0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-07-22T22:28:28.152422\n",
      "Starting job release. Current time:2020-07-22T22:28:29.825933\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 156\n",
      "[2020-07-22T22:28:29.844390] Entering context manager injector.\n",
      "Job release is complete. Current time:2020-07-22T22:28:31.552593\n",
      "\n",
      "StepRun(extract.py) Execution Summary\n",
      "======================================\n",
      "StepRun( extract.py ) Status: Finished\n",
      "{'runId': '329b2954-ed21-493f-8ee9-d2776f451dc0', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2020-07-22T22:26:49.939193Z', 'endTimeUtc': '2020-07-22T22:28:46.350697Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'b6d57d66-8764-4b95-9863-663420f7d4d1', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'b7d35166-f8b3-40ce-b825-51f34cb68afe', 'azureml.pipelinerunid': 'e953c74d-177e-4fb3-88de-fe5e9263b978', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'extract.py', 'useAbsolutePath': False, 'arguments': ['--output_extract', '$AZUREML_DATAREFERENCE_processed_mnist_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {'processed_mnist_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment MNIST-Model-Manual-Pipeline Environment', 'version': 'Autosave_2020-07-22T22:21:35Z_c16c3e16', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.9.0', 'numpy']}], 'name': 'azureml_87321baca1fc0bacb2b64d6c9ca03b94'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=%2BH3pscdQUZYDUNysAUmmJObg3pNvZ6mi0Kh9b6qLiVY%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=KMpUVltVW%2BvVhErp5LgzpK3lUwHxERmSddX3alyqn8Y%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'azureml-logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=h%2FdfGYxasEMTsM2FeTvf4mxT1QilFkUe5UqOii5rySM%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=IknlKklYTIGATf5sHZNDHa7AOi%2F2XUpBERyvsS%2Bq94E%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=ZIN1eoU87tfdF0N4gdS5cQFHJi%2B1CzK3iVOSUOI%2Fx%2BU%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=9IxzlyLbx6wz6b0qIWzW6119DcEmHmTJ11lKR61RDUI%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=6pegHHBFiwnahWb6Erl2TVKFGKAecvOfOE0EIW%2F7BCY%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'logs/azureml/111_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=E7XzYXSkhMfvO22JslgvQ6jtxgev3a1vYbY5CBxfS7U%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=xBp8nYu8OKGxBFabpFzEjuU6EOQ1y0j6bhh%2F0qL8Kv8%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=ROPj9wWLm2BU1BQ0d1t00X9IXpIgqs5qeUkV1zy7Nrc%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=QsLrtVcbsQy7AnrVF0d%2FYeGXAd%2F%2BlbgbLl4GkGIrMG0%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=KeXKsQmSut87l0%2Bti7XnObZmprrcvrWQXCNk6IBkv48%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.329b2954-ed21-493f-8ee9-d2776f451dc0/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=E7uGjJsDdfecq3jZZBbjnTracf0M%2FdvJPEazU2WxRGk%3D&st=2020-07-22T22%3A18%3A49Z&se=2020-07-23T06%3A28%3A49Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 3805a880-2419-494a-9b02-80e6d6f00f9d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/3805a880-2419-494a-9b02-80e6d6f00f9d?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\n",
      "StepRun( Training-Step ) Status: NotStarted\n",
      "StepRun( Training-Step ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      "========================================================================================================================\n",
      "1.13-cpu: Pulling from tensorflow\n",
      "16c48d79e9cc: Pulling fs layer\n",
      "3c654ad3ed7d: Pulling fs layer\n",
      "6276f4f9c29d: Pulling fs layer\n",
      "a4bd43ad48ce: Pulling fs layer\n",
      "e8d5220518a8: Pulling fs layer\n",
      "b89bc95dc4e6: Pulling fs layer\n",
      "874f36ef0b3a: Pulling fs layer\n",
      "20592f072a44: Pulling fs layer\n",
      "d5a9f64d93c8: Pulling fs layer\n",
      "bf16c69a1526: Pulling fs layer\n",
      "b47bfd667bdb: Pulling fs layer\n",
      "6a140fc11307: Pulling fs layer\n",
      "874f36ef0b3a: Waiting\n",
      "20592f072a44: Waiting\n",
      "d5a9f64d93c8: Waiting\n",
      "bf16c69a1526: Waiting\n",
      "b47bfd667bdb: Waiting\n",
      "6a140fc11307: Waiting\n",
      "a4bd43ad48ce: Waiting\n",
      "e8d5220518a8: Waiting\n",
      "b89bc95dc4e6: Waiting\n",
      "3c654ad3ed7d: Verifying Checksum\n",
      "3c654ad3ed7d: Download complete\n",
      "6276f4f9c29d: Download complete\n",
      "a4bd43ad48ce: Verifying Checksum\n",
      "a4bd43ad48ce: Download complete\n",
      "16c48d79e9cc: Verifying Checksum\n",
      "16c48d79e9cc: Download complete\n",
      "b89bc95dc4e6: Verifying Checksum\n",
      "b89bc95dc4e6: Download complete\n",
      "874f36ef0b3a: Verifying Checksum\n",
      "874f36ef0b3a: Download complete\n",
      "e8d5220518a8: Verifying Checksum\n",
      "e8d5220518a8: Download complete\n",
      "20592f072a44: Verifying Checksum\n",
      "20592f072a44: Download complete\n",
      "b47bfd667bdb: Verifying Checksum\n",
      "b47bfd667bdb: Download complete\n",
      "bf16c69a1526: Verifying Checksum\n",
      "bf16c69a1526: Download complete\n",
      "d5a9f64d93c8: Verifying Checksum\n",
      "d5a9f64d93c8: Download complete\n",
      "6a140fc11307: Verifying Checksum\n",
      "6a140fc11307: Download complete\n",
      "16c48d79e9cc: Pull complete\n",
      "3c654ad3ed7d: Pull complete\n",
      "6276f4f9c29d: Pull complete\n",
      "a4bd43ad48ce: Pull complete\n",
      "e8d5220518a8: Pull complete\n",
      "b89bc95dc4e6: Pull complete\n",
      "874f36ef0b3a: Pull complete\n",
      "20592f072a44: Pull complete\n",
      "d5a9f64d93c8: Pull complete\n",
      "bf16c69a1526: Pull complete\n",
      "b47bfd667bdb: Pull complete\n",
      "6a140fc11307: Pull complete\n",
      "Digest: sha256:a8598363b592586620449828598516d04540238b8bc50b7aac2a01cf3f9c7585\n",
      "Status: Downloaded newer image for viennaprivate.azurecr.io/tensorflow:1.13-cpu\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "[2020-07-22T22:30:24.715618] Entering context manager injector.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 108\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train.py ] with arguments: ['--input_data_location', '/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/3805a880-2419-494a-9b02-80e6d6f00f9d/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data', '--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.01', '--release_id', '0', '--model_name', 'tf_mnist_pipeline.model']\n",
      "After variable expansion, calling script [ train.py ] with arguments: ['--input_data_location', '/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/3805a880-2419-494a-9b02-80e6d6f00f9d/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data', '--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.01', '--release_id', '0', '--model_name', 'tf_mnist_pipeline.model']\n",
      "\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Argument input_data_location: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/3805a880-2419-494a-9b02-80e6d6f00f9d/mounts/workspaceblobstore/azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data\n",
      "Argument n_h1: 300\n",
      "Argument n_h2: 100\n",
      "Argument learning_rate: 0.01\n",
      "Argument batch_size: 50\n",
      "Argument release_id: 0\n",
      "Argument model_name: tf_mnist_pipeline.model\n",
      "Numpy binary data is loaded\n",
      "WARNING:tensorflow:From train.py:77: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2020-07-22 22:30:31.423122: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-07-22 22:30:31.428947: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294685000 Hz\n",
      "2020-07-22 22:30:31.429292: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c8480aa840 executing computations on platform Host. Devices:\n",
      "2020-07-22 22:30:31.429348: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-07-22 22:30:34.877415: W tensorflow/core/framework/allocator.cc:124] Allocation of 31360000 exceeds 10% of system memory.\n",
      "0 -- Training accuracy: 0.94 Validation accuracy: 0.9008\n",
      "2020-07-22 22:30:35.037329: W tensorflow/core/framework/allocator.cc:124] Allocation of 31360000 exceeds 10% of system memory.\n",
      "2020-07-22 22:30:38.483647: W tensorflow/core/framework/allocator.cc:124] Allocation of 31360000 exceeds 10% of system memory.\n",
      "1 -- Training accuracy: 0.96 Validation accuracy: 0.9209\n",
      "2020-07-22 22:30:38.617591: W tensorflow/core/framework/allocator.cc:124] Allocation of 31360000 exceeds 10% of system memory.\n",
      "2020-07-22 22:30:41.937995: W tensorflow/core/framework/allocator.cc:124] Allocation of 31360000 exceeds 10% of system memory.\n",
      "2 -- Training accuracy: 0.88 Validation accuracy: 0.9314\n",
      "3 -- Training accuracy: 0.92 Validation accuracy: 0.936\n",
      "4 -- Training accuracy: 0.96 Validation accuracy: 0.9436\n",
      "5 -- Training accuracy: 0.94 Validation accuracy: 0.9503\n",
      "6 -- Training accuracy: 0.96 Validation accuracy: 0.9528\n",
      "7 -- Training accuracy: 0.98 Validation accuracy: 0.9544\n",
      "8 -- Training accuracy: 1.0 Validation accuracy: 0.9591\n",
      "9 -- Training accuracy: 0.98 Validation accuracy: 0.9602\n",
      "10 -- Training accuracy: 1.0 Validation accuracy: 0.9623\n",
      "11 -- Training accuracy: 0.94 Validation accuracy: 0.9637\n",
      "12 -- Training accuracy: 0.98 Validation accuracy: 0.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 -- Training accuracy: 1.0 Validation accuracy: 0.9674\n",
      "14 -- Training accuracy: 1.0 Validation accuracy: 0.9668\n",
      "15 -- Training accuracy: 0.96 Validation accuracy: 0.967\n",
      "16 -- Training accuracy: 0.98 Validation accuracy: 0.9692\n",
      "17 -- Training accuracy: 1.0 Validation accuracy: 0.969\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-07-22T22:31:39.346335\n",
      "Starting job release. Current time:2020-07-22T22:31:40.290844\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 263\n",
      "[2020-07-22T22:31:40.304010] Entering context manager injector.\n",
      "Job release is complete. Current time:2020-07-22T22:31:41.266148\n",
      "\n",
      "StepRun(Training-Step) Execution Summary\n",
      "=========================================\n",
      "StepRun( Training-Step ) Status: Finished\n",
      "{'runId': '3805a880-2419-494a-9b02-80e6d6f00f9d', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2020-07-22T22:29:03.906615Z', 'endTimeUtc': '2020-07-22T22:31:47.855648Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'f37d3676-846e-4ff1-8038-f4d7bb30c21e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '114fa064-33a8-44ed-a9bc-2ecd8056a940', 'azureml.pipelinerunid': 'e953c74d-177e-4fb3-88de-fe5e9263b978', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'release_id': '0', 'run_type': 'train'}, 'inputDatasets': [], 'runDefinition': {'script': 'train.py', 'useAbsolutePath': False, 'arguments': ['--input_data_location', '$AZUREML_DATAREFERENCE_processed_mnist_data', '--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.01', '--release_id', '0', '--model_name', 'tf_mnist_pipeline.model'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {'processed_mnist_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/329b2954-ed21-493f-8ee9-d2776f451dc0/processed_mnist_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment MNIST-Model-Manual-Pipeline Environment', 'version': 'Autosave_2020-07-22T22:28:52Z_2b7f5321', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'tensorflow:1.13-cpu', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': 'viennaprivate.azurecr.io', 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': False}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=MiJYc%2BvFHQpkEWT38WEHNjdr6YZ7xvFxqNA4CicN%2BJs%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'azureml-logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/azureml-logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=18HrWyufNlZIzwGrPy3sWrzAoP2bYw7infQR5Vl0%2BbQ%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=6reFd%2Fi1VI1cJ0DX%2Bz9MEvhBW9IQmT%2FFzBYrrsIDJ9U%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=O5U%2B2rhoqV3dxyrG1ywzRWNBOoHEcM%2BgzKC2tAiLpyw%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=viKHyxUODgHh11wWzaVIn2V78DOGjz%2FuFSO1kLWfwaU%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=pABATLxAQMPLWKDzn0parcmMxwB3LW%2FXJUqM6jLpC54%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'logs/azureml/108_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/logs/azureml/108_azureml.log?sv=2019-02-02&sr=b&sig=Kz7C%2FP67PQxCz%2FWYKUo9OICAgZW4yBoTO%2FN8UTRIrKw%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'logs/azureml/azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=XKrLAG8ZlH65eGFvnDb8m7rNdo%2Fo8hfqLWoGH%2BlOgww%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Oaaw2WCg6fED8cvqJteGiyz%2FmRuyvcClDdVNQYJjMY0%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=hoY9Zz4RW0v8UGknB7P2YGZGtYqglY3H651u97fEyes%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.3805a880-2419-494a-9b02-80e6d6f00f9d/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=nsOXdErZ0RrPK3G84Hrl6JGXYpG320%2F3WEdL1bQfabI%3D&st=2020-07-22T22%3A21%3A51Z&se=2020-07-23T06%3A31%3A51Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: f230bd88-914b-41fb-9981-b073d9c91168\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/f230bd88-914b-41fb-9981-b073d9c91168?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StepRun( Evaluate and Register Model ) Status: NotStarted\n",
      "StepRun( Evaluate and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      "========================================================================================================================\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_2e1aa647468113323a439077734657c5\n",
      "Digest: sha256:5ad4c6cc73968982b57bceab23f46f13cfabb51a13e0184bea30c22104c89a53\n",
      "Status: Image is up to date for mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5:latest\n",
      "2020-07-22T22:32:05Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-07-22T22:32:05Z Starting output-watcher...\n",
      "2020-07-22T22:32:06Z a854f37e198c76f84b80fbbdf0c54f27337079746eb02a508e974e2772ec7ac6\n",
      "2020-07-22T22:32:06Z \n",
      "2020/07/22 22:32:06 Starting App Insight Logger for task:  containerSetup\n",
      "2020/07/22 22:32:06 Version: 3.0.01291.0001 Branch: hotfixChrisChange Commit: 03c8130a\n",
      "2020/07/22 22:32:06 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/07/22 22:32:06 sshd inside container not required for job, skipping setup.\n",
      "2020/07/22 22:32:07 All App Insights Logs was send successfully\n",
      "2020-07-22T22:32:11Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2020/07/22 22:32:02 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2020/07/22 22:32:02 Version: 3.0.01291.0001 Branch: hotfixChrisChange Commit: 03c8130a\n",
      ">>>   2020/07/22 22:32:02 DetonationChamber is not enabled on this subscription: b198933e-f055-498f-958d-0726ab11eddb\n",
      ">>>   2020/07/22 22:32:02 GPU count found: 0\n",
      ">>>   2020/07/22 22:32:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/config\n",
      ">>>   2020/07/22 22:32:02 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2020/07/22 22:32:02 Starting identity responder.\n",
      ">>>   2020/07/22 22:32:02 Starting identity responder.\n",
      ">>>   2020/07/22 22:32:02 Logfile used for identity responder: /mnt/batch/tasks/workitems/6abc5146-36bf-4951-a957-cde153147ff1/job-1/f230bd88-914b-41fb-9_48d4b79b-ccb9-4fb9-9613-96a98439036b/IdentityResponderLog-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      ">>>   2020/07/22 22:32:02 Logfile used for identity responder: /mnt/batch/tasks/workitems/6abc5146-36bf-4951-a957-cde153147ff1/job-1/f230bd88-914b-41fb-9_48d4b79b-ccb9-4fb9-9613-96a98439036b/IdentityResponderLog-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      ">>>   2020/07/22 22:32:02 Started Identity Responder for job.\n",
      ">>>   2020/07/22 22:32:02 Started Identity Responder for job.\n",
      ">>>   2020/07/22 22:32:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/wd\n",
      ">>>   2020/07/22 22:32:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/shared\n",
      ">>>   2020/07/22 22:32:02 Mounting job level file systems\n",
      ">>>   2020/07/22 22:32:02 Start to pulling docker image: mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5\n",
      ">>>   2020/07/22 22:32:02 Requesting XDS for registry details.\n",
      ">>>   2020/07/22 22:32:02 Attempt 1 of http call to https://westus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourceGroups/mlops_template/workspaces/mlops_template_ml/clusters/cpucluster/nodes/tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d?api-version=2018-02-01\n",
      ">>>   2020/07/22 22:32:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts\n",
      ">>>   2020/07/22 22:32:02 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/config/.amlcompute.datastorecredentials\n",
      ">>>   2020/07/22 22:32:02 Datastore credentials file not found, skipping.\n",
      ">>>   2020/07/22 22:32:02 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/config/.master.runtimesastokens\n",
      ">>>   2020/07/22 22:32:02 Runtime sas tokens file not found, skipping.\n",
      ">>>   2020/07/22 22:32:02 No NFS configured\n",
      ">>>   2020/07/22 22:32:02 No Azure File Shares configured\n",
      ">>>   2020/07/22 22:32:02 Mounting blob file systems\n",
      ">>>   2020/07/22 22:32:02 Mounting azureml-blobstore-e0b2e73c-0bd4-4cf1-8982-4e6dd93ea64e container from mlopstemplatem0353086450 account at /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore\n",
      ">>>   2020/07/22 22:32:02 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/07/22 22:32:02 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/07/22 22:32:02 Running following command: &{/bin/bash [bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/configs/workspaceblobstore.cfg --log-level=LOG_WARNING] []  <nil>   [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/07/22 22:32:03 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore\n",
      ">>>   2020/07/22 22:32:03 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore\n",
      ">>>   2020/07/22 22:32:03 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2020/07/22 22:32:03 Got container registry details from credentials service.\n",
      ">>>   2020/07/22 22:32:03 Writing ACR Details to file...\n",
      ">>>   2020/07/22 22:32:03 Copying ACR Details file to worker nodes...\n",
      ">>>   2020/07/22 22:32:03 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2020/07/22 22:32:03 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2020/07/22 22:32:03 Successfully mounted azureml-blobstore-e0b2e73c-0bd4-4cf1-8982-4e6dd93ea64e container from mlopstemplatem0353086450 account at /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore\n",
      ">>>   2020/07/22 22:32:03 No unmanaged file systems configured\n",
      ">>>   2020/07/22 22:32:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/azureml_compute_logs\n",
      ">>>   2020/07/22 22:32:05 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/logs\n",
      ">>>   2020/07/22 22:32:05 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/outputs\n",
      ">>>   2020/07/22 22:32:05 Starting output-watcher...\n",
      ">>>   2020/07/22 22:32:06 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2020/07/22 22:32:06 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name f230bd88-914b-41fb-9981-b073d9c91168 -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/workitems/6abc5146-36bf-4951-a957-cde153147ff1/job-1/f230bd88-914b-41fb-9_48d4b79b-ccb9-4fb9-9613-96a98439036b/certs:/mnt/batch/tasks/workitems/6abc5146-36bf-4951-a957-cde153147ff1/job-1/f230bd88-914b-41fb-9_48d4b79b-ccb9-4fb9-9613-96a98439036b/certs -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/azureml_compute_logs -v /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168:/mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168 -v /mnt/batch/tasks/workitems/6abc5146-36bf-4951-a957-cde153147ff1/job-1/f230bd88-914b-41fb-9_48d4b79b-ccb9-4fb9-9613-96a98439036b/wd:/mnt/batch/tasks/workitems/6abc5146-36bf-4951-a957-cde153147ff1/job-1/f230bd88-914b-41fb-9_48d4b79b-ccb9-4fb9-9613-96a98439036b/wd -v /opt/azureml:/opt/azureml:ro -w /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/config/.batchai.envlist --shm-size 2g -d -it --privileged --net=host mlopstemplat9c2637c6.azurecr.io/azureml/azureml_2e1aa647468113323a439077734657c5\n",
      ">>>   2020/07/22 22:32:06 a854f37e198c76f84b80fbbdf0c54f27337079746eb02a508e974e2772ec7ac6\n",
      ">>>   2020/07/22 22:32:06 \n",
      ">>>   2020/07/22 22:32:07 Container ssh is not required for job type.\n",
      ">>>   2020/07/22 22:32:07 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/azureml_compute_logs\n",
      ">>>   2020/07/22 22:32:07 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94/bin/python $AZ_BATCHAI_INPUT_AZUREML/f230bd88-914b-41fb-9981-b073d9c91168-setup/job_prep.py --snapshots '[{\"Id\":\"eb703a41-9367-4922-97f9-f359b4295631\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/07/22 22:32:07 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/azureml_compute_logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      ">>>   2020/07/22 22:32:07 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168/azureml_compute_logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      ">>>   2020/07/22 22:32:07 runSpecialJobTask: Running cmd: &{/usr/bin/docker [docker exec -t f230bd88-914b-41fb-9981-b073d9c91168 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/mlops_template_ml/azureml/f230bd88-914b-41fb-9981-b073d9c91168/mounts/workspaceblobstore/azureml/f230bd88-914b-41fb-9981-b073d9c91168;/azureml-envs/azureml_87321baca1fc0bacb2b64d6c9ca03b94/bin/python $AZ_BATCHAI_INPUT_AZUREML/f230bd88-914b-41fb-9981-b073d9c91168-setup/job_prep.py --snapshots '[{\"Id\":\"eb703a41-9367-4922-97f9-f359b4295631\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'] []  <nil> <nil> <nil> [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:08.087260] Entering job preparation.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:08.655494] Starting job preparation.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:08.655535] Extracting the control code.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:08.683702] fetching and extracting the control code on master node.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.551813] Retrieving project from snapshot: eb703a41-9367-4922-97f9-f359b4295631\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 50\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.552793] Start RetrieveProjectSasUrls\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.783588] Finished RetrieveProjectSasUrls\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.785265] Starting project file download.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.855127] Finished project file download.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.869537] Finished fetching and extracting the control code.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.872595] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.873711] Start run_history_prep.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:09.923257] Entering context manager injector.\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:10.683534] downloadDataStore completed\n",
      ">>>   2020/07/22 22:32:10 runSpecialJobTask: preparation: [2020-07-22T22:32:10.686313] Job preparation is complete.\n",
      ">>>   2020/07/22 22:32:11 All App Insights Logs was send successfully\n",
      ">>>   2020/07/22 22:32:11 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2020-07-22T22:32:11Z 127.0.0.1 slots=2 max-slots=2\n",
      "2020-07-22T22:32:11Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-07-22T22:32:22.369639\n",
      "Starting job release. Current time:2020-07-22T22:32:24.061691\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 151\n",
      "[2020-07-22T22:32:24.075012] Entering context manager injector.\n",
      "Job release is complete. Current time:2020-07-22T22:32:25.417774\n",
      "\n",
      "StepRun(Evaluate and Register Model) Execution Summary\n",
      "=======================================================\n",
      "StepRun( Evaluate and Register Model ) Status: Finished\n",
      "{'runId': 'f230bd88-914b-41fb-9981-b073d9c91168', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2020-07-22T22:32:07.189085Z', 'endTimeUtc': '2020-07-22T22:32:31.305839Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'eb703a41-9367-4922-97f9-f359b4295631', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'a393d26f-8711-440c-b088-5964de8bce40', 'azureml.pipelinerunid': 'e953c74d-177e-4fb3-88de-fe5e9263b978', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'evaluate_model.py', 'useAbsolutePath': False, 'arguments': ['--release_id', '0', '--model_name', 'tf_mnist_pipeline.model'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment MNIST-Model-Manual-Pipeline Environment', 'version': 'Autosave_2020-07-22T22:21:35Z_c16c3e16', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.9.0', 'numpy']}], 'name': 'azureml_87321baca1fc0bacb2b64d6c9ca03b94'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/azureml-logs/55_azureml-execution-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=hjE45zxdduaSaV%2FYGyvVO5EbR0c0up%2FE9lzXcAR9%2BHU%3D&st=2020-07-22T22%3A22%3A37Z&se=2020-07-23T06%3A32%3A37Z&sp=r', 'azureml-logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/azureml-logs/65_job_prep-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=g3snKfdwFw0RHj9s38xlABR59fe1%2BNrb6c%2BFLURpjig%3D&st=2020-07-22T22%3A22%3A37Z&se=2020-07-23T06%3A32%3A37Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=tU8dsoiwR%2F2mC1edvVf836L6YifWdaYir32LyqO82lA%3D&st=2020-07-22T22%3A22%3A37Z&se=2020-07-23T06%3A32%3A37Z&sp=r', 'azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/azureml-logs/75_job_post-tvmps_1f626ef4e87a5e3b695a9c76c6f8c9788cf2c638d1386b9b8218a6adf8189b7b_d.txt?sv=2019-02-02&sr=b&sig=feFP3DyDdDOr1oGcfOCE4FI2SrgWBre4WA66Onw99WU%3D&st=2020-07-22T22%3A22%3A37Z&se=2020-07-23T06%3A32%3A37Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=rYpJAZPk7hQjFiuxAsCB6pQ0G2%2FqLJOIMDch8u4uAA0%3D&st=2020-07-22T22%3A22%3A37Z&se=2020-07-23T06%3A32%3A37Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=WiesyxeqFRxBaNoH%2B%2F9cZjyTJJOZnHBeUYsltBH8isI%3D&st=2020-07-22T22%3A22%3A37Z&se=2020-07-23T06%3A32%3A37Z&sp=r', 'logs/azureml/105_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/logs/azureml/105_azureml.log?sv=2019-02-02&sr=b&sig=B2fW9fTULI31DEN3wJyrRgbQzTdWtc0%2B0m%2BCnDPQtMk%3D&st=2020-07-22T22%3A22%3A38Z&se=2020-07-23T06%3A32%3A38Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ZKPK685DibYKMLLABjVX8C%2FzlktEZ9uuOhhXY8Ob8Sc%3D&st=2020-07-22T22%3A22%3A38Z&se=2020-07-23T06%3A32%3A38Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=vylhXq6C5rCEQadPvLW0%2BQJNcA5rSjvsFRsV4AHrxIQ%3D&st=2020-07-22T22%3A22%3A38Z&se=2020-07-23T06%3A32%3A38Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=h0XEzIVtXP66S4KrecfZb%2FrckU6PZseS0d06Vu9vww0%3D&st=2020-07-22T22%3A22%3A38Z&se=2020-07-23T06%3A32%3A38Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=xHkU%2Fd64FJzIWp3pNvrELr7fZ%2BJupYGb8n7dlAe9Eu4%3D&st=2020-07-22T22%3A22%3A38Z&se=2020-07-23T06%3A32%3A38Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.f230bd88-914b-41fb-9981-b073d9c91168/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=FBqt9ia2dePGxc9Veanmw%2FzLpXz6NPZK5bwne1w2ios%3D&st=2020-07-22T22%3A22%3A38Z&se=2020-07-23T06%3A32%3A38Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'e953c74d-177e-4fb3-88de-fe5e9263b978', 'status': 'Completed', 'startTimeUtc': '2020-07-22T22:21:18.984713Z', 'endTimeUtc': '2020-07-22T22:32:36.726269Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.e953c74d-177e-4fb3-88de-fe5e9263b978/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rnZg3mpMrR0UmvkftNFna7%2BhqziM09rQB9FTHtMqU%2FM%3D&st=2020-07-22T22%3A22%3A40Z&se=2020-07-23T06%3A32%3A40Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.e953c74d-177e-4fb3-88de-fe5e9263b978/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=FKKk8G75CZJfbbARgfq1pWampH2Fq9sHWnlveJa9E7o%3D&st=2020-07-22T22%3A22%3A40Z&se=2020-07-23T06%3A32%3A40Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatem0353086450.blob.core.windows.net/azureml/ExperimentRun/dcid.e953c74d-177e-4fb3-88de-fe5e9263b978/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=3Ejk7164jrR3tFM9CnTozYZojBJhocSkitUZ%2BHZlb6Q%3D&st=2020-07-22T22%3A22%3A40Z&se=2020-07-23T06%3A32%3A40Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True, raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Publish and trigger a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Pipeline is executed once under an experiment. But for later use, you may want to Publish the Pipeline as an Endpoint. publish_pipeline method publishes a pipeline under Pipeline section of Workspace. The published pipeline can later be called from any where inside or outside of Azure.\n",
    "\n",
    "One of the use-cases is to call the Pipeline within a Data Engineering Pipeline. So the Data Engineering team can trigger the piblished pipeline by having the URI information of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(name=\"MNIST-Pipeline-Manually-Built-Manulife\", \n",
    "                                                   description=\"Steps are: data preparation, training, model validation and model registration\", \n",
    "                                                   version=\"0.1\", \n",
    "                                                   continue_on_step_failure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>MNIST-Pipeline-Manually-Built-Manulife</td><td><a href=\"https://ml.azure.com/pipelines/b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3?wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML\" target=\"_blank\" rel=\"noopener\">b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3</a></td><td>Active</td><td><a href=\"https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourceGroups/MLOps_Template/providers/Microsoft.MachineLearningServices/workspaces/MLOps_template_ML/PipelineRuns/PipelineSubmit/b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: MNIST-Pipeline-Manually-Built-Manulife,\n",
       "Id: b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3,\n",
       "Status: Active,\n",
       "Endpoint: https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourceGroups/MLOps_Template/providers/Microsoft.MachineLearningServices/workspaces/MLOps_template_ML/PipelineRuns/PipelineSubmit/b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "\n",
    "pipeline_id = published_pipeline.id # use your published pipeline id\n",
    "published_pipeline = PublishedPipeline.get(ws, pipeline_id)\n",
    "published_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the endpoint that is callable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourceGroups/MLOps_Template/providers/Microsoft.MachineLearningServices/workspaces/MLOps_template_ML/PipelineRuns/PipelineSubmit/b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "rest_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call the Endpoint from anywhere. In order to call the endpoint, you need to authenticate yourself. There are two ways to do that:\n",
    "    \n",
    "    1. InteractiveLoginAuthentication\n",
    "    1. ServicePrincipalAuthentication\n",
    "    \n",
    "The first one requires you to authentical yourself interactively or be already authenticated. As we're already authenticated, so we can use the first approach. The second approach id described in the next section.\n",
    "\n",
    "The InteractiveLoginAuthentication class can help us generate the authentication key required to connect with the ML Pipeline Endpoint using **get_authentication_header** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "import requests\n",
    "\n",
    "auth = InteractiveLoginAuthentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Imh1Tjk1SXZQZmVocTM0R3pCRFoxR1hHaXJuTSIsImtpZCI6Imh1Tjk1SXZQZmVocTM0R3pCRFoxR1hHaXJuTSJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC9lNjU5MjJmOS00YmQ0LTRmMTEtYjFhMy00OGU4OWQ3NTY3NGUvIiwiaWF0IjoxNTk1NTE1MjcwLCJuYmYiOjE1OTU1MTUyNzAsImV4cCI6MTU5NTUxOTE3MCwiYWNyIjoiMSIsImFpbyI6IkFXUUFtLzhRQUFBQTBxVDI2Yi95eHp0ekl5eXllTmpRL0hhbjBYV3BIWW1lYmpKcTF4UHZyMTZwTit5OGljRE01RnExUUtKWm9FVVNOQ1ZhTmdvYzNGa2lIRmtoM0xUZFo2THY3eTZ4cW9BRGRrNEo1ZlQ0dThRdjZwMnQwZGJBV2NsUm1pYy9LT1hOIiwiYWx0c2VjaWQiOiI1OjoxMDAzQkZGREFGMEIzODQ1IiwiYW1yIjpbInB3ZCIsIndpYSJdLCJhcHBpZCI6IjA0YjA3Nzk1LThkZGItNDYxYS1iYmVlLTAyZjllMWJmN2I0NiIsImFwcGlkYWNyIjoiMCIsImVtYWlsIjoibmlsb29mYXIubmF5ZWJpQGF2YW5hZGUuY29tIiwiaWRwIjoiaHR0cHM6Ly9zdHMud2luZG93cy5uZXQvY2YzNjE0MWMtZGRkNy00NWE3LWIwNzMtMTExZjY2ZDBiMzBjLyIsImlwYWRkciI6Ijc1LjE1NS41OC45MyIsIm5hbWUiOiJOaWxvb2ZhciBOYXllYmkiLCJvaWQiOiIyYjYyMDc3ZC02MGVkLTRkNzktODdmNC0zZmY3NDBmMzQyMzQiLCJwdWlkIjoiMTAwMzIwMDA0OUQ3NjE0MCIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInN1YiI6Il9kZW1DekxGU1g5emFlVmlwOUZHaDU0NmJwdGpPY05CUHNVNWVoSDNEQUEiLCJ0aWQiOiJlNjU5MjJmOS00YmQ0LTRmMTEtYjFhMy00OGU4OWQ3NTY3NGUiLCJ1bmlxdWVfbmFtZSI6Im5pbG9vZmFyLm5heWViaUBhdmFuYWRlLmNvbSIsInV0aSI6Ind5VndySDhJT2tPdThrdlZSTll5QUEiLCJ2ZXIiOiIxLjAifQ.n4uhAmNtUnjgnAkxlrMMchwpCB8Qiw0j6AO6KupvOePw_UD2nGvuK4KKHqSGojJ-pmwg3yiWhkTgj4RlKTwuzvwizWG1suiV2Ko7-ccpooltKZ2DzAN_4GdcdvyhI2-8ehdwPnuK97FbWoX6fg4emfx_sJOlD2NGPut_6fZloO4-1qzoVQfOg1iwvbt2kFQI1klw2t8zEdm0xxYz8ZKQKGmvQP08a9sShZ3UJ3lWQ0x9EHkt7J8sSHGkXkuE8UoggLOT68pyTVzqF_nlhxIAtQNoGNHTQy_FNSHO1bgASJEhNkt35IB5QXTrfzLgCBDakqnPI6YE68wZOsqutkJMjw'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aad_token = auth.get_authentication_header()\n",
    "aad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally using a simple post request, you can trigger the pipeline. Post request are available in any modern programming language, therefore, you can trigger the pipeline from anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the param when running the pipeline\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=aad_token, \n",
    "                         json={\"ExperimentName\": \"Kicked_MNist_Pipeline_Remotely\",\n",
    "                               \"RunSource\": \"SDK\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6fcf3a40-643e-4354-925c-f347fc11a6e4\n"
     ]
    }
   ],
   "source": [
    "run_id = response.json()[\"Id\"]\n",
    "\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Description': None,\n",
       " 'Status': {'StatusCode': 0,\n",
       "  'StatusDetail': None,\n",
       "  'CreationTime': '2020-07-23T15:10:10.7650029Z',\n",
       "  'EndTime': None},\n",
       " 'GraphId': '7cdc9871-ed0b-4cf0-8530-ec64b8d49652',\n",
       " 'IsSubmitted': False,\n",
       " 'HasErrors': False,\n",
       " 'HasWarnings': False,\n",
       " 'UploadState': 0,\n",
       " 'ParameterAssignments': {},\n",
       " 'DataPathAssignments': {},\n",
       " 'DataSetDefinitionValueAssignments': {},\n",
       " 'RunHistoryExperimentName': 'Kicked_MNist_Pipeline_Remotely',\n",
       " 'PipelineId': 'b29d20d0-04e9-4c29-bc44-fb8bc3eb43c3',\n",
       " 'RunSource': 'SDK',\n",
       " 'RunType': 0,\n",
       " 'TotalRunSteps': 3,\n",
       " 'ScheduleId': None,\n",
       " 'RunUrl': 'https://ml.azure.com/experiments/Kicked_MNist_Pipeline_Remotely/runs/6fcf3a40-643e-4354-925c-f347fc11a6e4?tid=e65922f9-4bd4-4f11-b1a3-48e89d75674e&wsid=/subscriptions/b198933e-f055-498f-958d-0726ab11eddb/resourcegroups/MLOps_Template/workspaces/MLOps_template_ML',\n",
       " 'tags': {},\n",
       " 'StepTags': {},\n",
       " 'Properties': {},\n",
       " 'StepProperties': {},\n",
       " 'CreatedBy': {'UserObjectId': '2b62077d-60ed-4d79-87f4-3ff740f34234',\n",
       "  'UserTenantId': 'e65922f9-4bd4-4f11-b1a3-48e89d75674e',\n",
       "  'UserName': 'Niloofar Nayebi'},\n",
       " 'EntityStatus': 0,\n",
       " 'Id': '6fcf3a40-643e-4354-925c-f347fc11a6e4',\n",
       " 'Etag': '\"ad00d844-0000-0800-0000-5f19a8520000\"',\n",
       " 'CreatedDate': '2020-07-23T15:10:10.7654005Z',\n",
       " 'LastModifiedDate': '2020-07-23T15:10:10.7654005Z'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the Pipeline Run:\n",
    "\n",
    "from azureml.pipeline.core import PipelineRun\n",
    "\n",
    "exp = Experiment(name=\"Kicked_MNist_Pipeline_Remotely\", workspace=ws)\n",
    "pipeline_run = PipelineRun(experiment=exp, run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Schedule the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of using a Pipeline is to schedule it. In the example below, the pipeline is scheduled to be triggered weekly on Fridays at 15:30 UTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "# \n",
    "# \n",
    "# recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Friday\"], time_of_day=\"15:30\")\n",
    "# schedule = Schedule.create(ws, name=\"ScheduledPipeline\", pipeline_id=pipeline_id,\n",
    "#                               experiment_name=\"MNIST-Pipeline-Wekly-Scheduled\", recurrence=recurrence)\n",
    "# \n",
    "## Get the list of scheduled Pipelines\n",
    "# Schedule.list(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Users/niloofar.nayebi/PROJECT/10-AltaGas-MLops/build-release-ci-cd-master/.git/\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#! git init\n",
    "## connect to gitHub\n",
    "! ssh-keygen -t rsa -C \"niloofar.nayebi@avanade.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 182fdbe] Pipeline published and scheduled\n",
      " 1 file changed, 4 insertions(+), 70 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in MLPipeline_MNIST.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": [
    "! git remote add origin git@github.com:user/MLOpsPython.git\n",
    "! git add . && git commit -m \"Pipeline published and scheduled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Host key verification failed.\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": [
    "! git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete compute resources\n",
    "\n",
    "Once this exercise is completed, you can delete disposable resources so you avoid getting unnecessary charges.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_cpu.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
